{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "#import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "import glob\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "input_dir = \"./advanced_ML/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_dir + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def classid2label(class_id):\n",
    "    category, *attribute = class_id.split(\"_\")\n",
    "    return category, attribute\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def json2df(data):\n",
    "    df = pd.DataFrame()\n",
    "    for index, el in enumerate(data):\n",
    "        for key, val in el.items():\n",
    "            df.loc[index, key] = val\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "input_dir = \"advanced_ML/data/\"\n",
    "train_df = pd.read_csv(input_dir + \"train.csv\")\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "\n",
    "with open(input_dir + \"label_descriptions.json\") as f:\n",
    "    label_description = json.load(f)\n",
    "    \n",
    "print(\"this dataset info\")\n",
    "print(json.dumps(label_description[\"info\"], indent=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "category_df = json2df(label_description[\"categories\"])\n",
    "category_df[\"id\"] = category_df[\"id\"].astype(int)\n",
    "category_df[\"level\"] = category_df[\"level\"].astype(int)\n",
    "attribute_df = json2df(label_description[\"attributes\"])\n",
    "attribute_df[\"id\"] = attribute_df[\"id\"].astype(int)\n",
    "attribute_df[\"level\"] = attribute_df[\"level\"].astype(int)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"Category Labels\")\n",
    "#category_df\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"Attribute Labels\")\n",
    "#attribute_df\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#sample_rle_encoding=train_df['EncodedPixels'][0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "counter_category = Counter()\n",
    "counter_attribute = Counter()\n",
    "for class_id in train_df[\"ClassId\"]:\n",
    "    category, attribute = classid2label(class_id)\n",
    "    counter_category.update([category])\n",
    "    counter_attribute.update(attribute)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "category_name_dict = {}\n",
    "for i in label_description[\"categories\"]:\n",
    "    category_name_dict[str(i[\"id\"])] = i[\"name\"]\n",
    "attribute_name_dict = {}\n",
    "for i in label_description[\"attributes\"]:\n",
    "    attribute_name_dict[str(i[\"id\"])] = i[\"name\"]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "ROOT_DIR=\"fashion/mrcnn\"\n",
    "DATA_DIR=\"advanced_ML/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FashionDataset(utils.Dataset):\n",
    "    def load_fashion(self,image_ids=None,num_data=None):\n",
    "        '''\n",
    "        add_class --> register 46 classes self.add_class('fashion',i,name)\n",
    "        image_ids --> unique index of images(name?)\n",
    "        self.add_image('fashion',image_ids,width,height,annotations)\n",
    "        width,height --> shape[:2] or extract form dataframe\n",
    "        annotations --> all collections of annotations for each image\n",
    "        Todo:\n",
    "        There are some rows that have height and weight as nan value\n",
    "        validation option is necessary for training\n",
    "        '''\n",
    "        for i,row in category_df.iterrows():\n",
    "            self.add_class('fashion',i,row['name'])\n",
    "        \n",
    "        if image_ids is None:\n",
    "            image_ids = list(set(train_df['ImageId']))\n",
    "        \n",
    "        if num_data is not None:\n",
    "            random.seed(42)\n",
    "            random.shuffle(image_ids)\n",
    "            image_ids=image_ids[:num_data]\n",
    "            \n",
    "            \n",
    "        for i in image_ids:\n",
    "            Width = train_df[train_df['ImageId']==i]['Width'].reset_index(drop=True)[0]\n",
    "            Height = train_df[train_df['ImageId']==i]['Height'].reset_index(drop=True)[0]\n",
    "            self.add_image('fashion',\n",
    "                           image_id=i,\n",
    "                           path=DATA_DIR+'/train/'+i,\n",
    "                           width=Width,\n",
    "                           height=Height,\n",
    "                           annotations=train_df[train_df['ImageId']==i])\n",
    "        \n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        ImagePath = info['path']\n",
    "        image = np.asarray(Image.open(ImagePath).convert(\"RGB\"))\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        width=info['width']\n",
    "        height=info['height']\n",
    "        \n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for i,annotation in annotations.iterrows():\n",
    "            class_id=annotation['ClassId']\n",
    "            class_id=class_id.split('_')[0]\n",
    "            class_ids.append(class_id)\n",
    "            rle = annotation['EncodedPixels']\n",
    "            instance_masks.append(self.rle_to_mask(rle,width,height))\n",
    "            \n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)+1\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            # Call super class to return an empty mask\n",
    "            return super(FashionDataset, self).load_mask(image_id)\n",
    "        \n",
    "        \n",
    "    def rle_to_mask(self,rle,width,height):\n",
    "        mask = np.zeros(width*height,dtype=np.int8)\n",
    "        pixels_list = list(map(int,rle.split(\" \")))\n",
    "        for i in range(0,len(pixels_list),2):\n",
    "            start_pixel = pixels_list[i]-1\n",
    "            num_pixel = pixels_list[i+1]-1\n",
    "            mask[start_pixel:start_pixel+num_pixel] = 1\n",
    "        \n",
    "        mask = mask.reshape((height,width),order='F')\n",
    "        return mask\n",
    "    \n",
    "    def load_attributes(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        \n",
    "        return annotations['ClassId'].apply(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image_ids_list = list(set(train_df['ImageId']))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(image_ids_list)\n",
    "\n",
    "val_split = 0.1\n",
    "split = int((1-val_split)*len(image_ids_list))\n",
    "\n",
    "#train_ids = image_ids_list[:]\n",
    "val_ids = image_ids_list[split:]\n",
    "#train_ids = train_ids[:3000]\n",
    "val_ids = val_ids[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fashion_dataset_train = FashionDataset()\n",
    "#fashion_dataset_train.load_fashion(train_ids)\n",
    "fashion_dataset_val = FashionDataset()\n",
    "fashion_dataset_val.load_fashion(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FashionConfig(Config):\n",
    "\n",
    "    NAME = \"fashion\"\n",
    "\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 46\n",
    "    STEPS_PER_EPOCH=100\n",
    "\n",
    "\n",
    "class InferenceConfig(FashionConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "    \n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config,model_dir=ROOT_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "#model_path = model.find_last()\n",
    "# print(\"Loading weights from \", model_path)\n",
    "#model_path='fashion/mrcnn/fashion20190608T2206/mask_rcnn_fashion_0044.h5'\n",
    "#model_path='fashion/mrcnn/pre-trained/mask_rcnn_fashion_0015.h5'\n",
    "model_path='fashion/mrcnn/fashion20190613T0413/mask_rcnn_fashion_0030.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fashion_dataset_val.prepare()\n",
    "#fashion_dataset_train.image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(fashion_dataset_val.image_ids, 100)\n",
    "Apss=[]\n",
    "for iou in tqdm(np.arange(0.5,1,0.05)):\n",
    "    APs = []\n",
    "    for image_id in image_ids:\n",
    "        # Load image and ground truth data\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(fashion_dataset_val, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],iou_threshold=iou)\n",
    "        APs.append(AP)\n",
    "    \n",
    "    Apss.append(np.mean(APs))\n",
    "# plt.plot(np.arange(0.5,1,0.05),Apss)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plt.plot(np.arange(0.5,1,0.05),Apss)\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ids=np.random.choice(fashion_dataset_train.image_ids,10)\n",
    "img = fashion_dataset_train.load_image(img_ids[6])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls fashion/realdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=np.array(Image.open('fashion/realdata/chams.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=np.rot90(img,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#i=6\n",
    "\n",
    "#visualize.display_instances(img, np.expand_dims(r['rois'][i],0), np.expand_dims(r['masks'][:,:,i],-1), np.array([r['class_ids'][i]]), \n",
    "#                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "bboxs=r['rois']\n",
    "raw_masks=r['raw_masks']\n",
    "molded_masks=r['masks']\n",
    "img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "probs=r['raw_masks']\n",
    "bbi=r['rois'][5]\n",
    "bbimg=img[bbi[0]:bbi[2],bbi[1]:bbi[3]]\n",
    "bbprobs=probs[:,:,5][bbi[0]:bbi[2],bbi[1]:bbi[3]]\n",
    "bbprobs.sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "a=np.expand_dims(probs[:,:,0],0)\n",
    "a=np.append(1-a,a,axis=0)\n",
    "np.log((a[1]+1e-5)).sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def portion(mask):\n",
    "    h,w=mask.shape\n",
    "    return mask.sum()/(h*w)\n",
    "#25% okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "\n",
    "def dense_crf(img, output_probs):\n",
    "    h = output_probs.shape[0]\n",
    "    w = output_probs.shape[1]\n",
    "\n",
    "    output_probs = np.expand_dims(output_probs, 0)\n",
    "    output_probs = np.append(1 - output_probs, output_probs, axis=0)\n",
    "    #output_probs[1] = output_probs[1]+1e-4\n",
    "    d = dcrf.DenseCRF2D(w, h, 2)\n",
    "    U = -np.log(output_probs)\n",
    "    U = U.reshape((2, -1))\n",
    "    U = np.ascontiguousarray(U)\n",
    "    #print(U.sum())\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    d.setUnaryEnergy(U.astype(np.float32))\n",
    "\n",
    "    d.addPairwiseGaussian(sxy=20, compat=3)\n",
    "    d.addPairwiseBilateral(sxy=30, srgb=20, rgbim=img, compat=10)\n",
    "\n",
    "    Q = d.inference(20)\n",
    "    Q = np.argmax(np.array(Q,dtype=np.float32), axis=0).reshape((h, w))\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the submission system does not permit overlapped masks, we have to fix them\n",
    "def refine_masks(masks,scores):\n",
    "    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n",
    "    #mask_index = np.argsort(areas)\n",
    "    mask_index = np.argsort(scores)[::-1]\n",
    "    #print(mask_index)\n",
    "    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n",
    "    for m in mask_index:\n",
    "        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n",
    "        union_mask = np.logical_or(masks[:, :, m], union_mask)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = \"fashion/\"\n",
    "sample_df = pd.read_csv(input_dir + \"sample_submission.csv\")\n",
    "'1554' '1764''2184' '984'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_df['ImageId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=model.detect([img])\n",
    "r = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(DATA_DIR+\"/test/\"+sample_df['ImageId'][101]))\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "height,width,_=img.shape\n",
    "if height*width > (1024*1024):\n",
    "    resize_scale=math.sqrt((height*width)/(1024*1024))\n",
    "    new_height = int(height/resize_scale)\n",
    "    new_width = int(width/resize_scale)\n",
    "    print(height,new_height)\n",
    "    print(width,new_width)\n",
    "    img = cv2.resize(img, dsize=(new_width,new_height))\n",
    "\n",
    "\n",
    "\n",
    "result=model.detect([img])\n",
    "r = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names=['BG', 'shirt', 'top', 'sweater', 'cardigan', 'jacket', 'vest', 'pants', 'shorts', 'skirt', 'coat', 'dress', 'jumpsuit', 'cape',\n",
    " 'glasses', 'hat', 'headband', 'tie', 'glove', 'watch', 'belt', 'leg warmer', 'tights', 'sock', 'shoe', 'bag', 'scarf', 'umbrella', 'hood',\n",
    " 'collar', 'lapel', 'epaulette', 'sleeve', 'pocket', 'neckline', 'buckle', 'zipper', 'applique', 'bead', 'bow', 'flower', 'fringe',\n",
    " 'ribbon', 'rivet', 'ruffle', 'sequin', 'tassel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r['class_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_SCORE=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "molded_masks=r['masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "#raw_masks=r['raw_masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "molded_masks=refine_masks(molded_masks,r['scores'][r['scores']>THRESHOLD_SCORE])\n",
    "\n",
    "i=(r['scores']>THRESHOLD_SCORE).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(img, r['rois'][:i], molded_masks, r['class_ids'][:i], \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=3\n",
    "if i > -1:\n",
    "    visualize.display_instances(img, np.expand_dims(r['rois'][i],0), np.expand_dims(molded_masks[:,:,i],-1), np.expand_dims(r['class_ids'][i],0), \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug=False\n",
    "if debug:\n",
    "    raw_masks = raw_masks*molded_masks\n",
    "#plt.imshow(raw_masks[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(raw_masks<0.01).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboxs=r['rois']\n",
    "\n",
    "i=4\n",
    "if i > -1:\n",
    "    img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "    mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "    molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "    if portion(molded_mask) < 0.2:\n",
    "        keep += 1\n",
    "    mask_seg = mask_seg+1e-9\n",
    "    Q = dense_crf(img_seg,mask_seg)\n",
    "    molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "\n",
    "    visualize.display_instances(img, np.expand_dims(r['rois'][i],0), np.expand_dims(molded_masks[:,:,i],-1), np.expand_dims(r['class_ids'][i],0), \n",
    "                                class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bboxs=r['rois']\n",
    "#raw_masks=r['raw_masks']\n",
    "#molded_masks=r['masks']\n",
    "\n",
    "keep=[]\n",
    "\n",
    "for i in range(raw_masks.shape[-1]):\n",
    "    if r['scores'][i] > THRESHOLD_SCORE:\n",
    "        img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "        mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "        molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "        if portion(molded_mask) < 0.2:\n",
    "            if portion(molded_mask) < 0.05:\n",
    "                keep.append(False)\n",
    "                continue\n",
    "        keep.append(True)\n",
    "    \n",
    "        #mask_seg = mask_seg+1e-9\n",
    "        #Q = dense_crf(img_seg,mask_seg)\n",
    "        #if Q.sum() > 0:\n",
    "        #    if abs(portion(molded_mask)-portion(Q)/portion(molded_mask)) > 0.5:\n",
    "        #        keep.append(True)\n",
    "                #print(abs(molded_mask.sum()-Q.sum()/molded_mask.sum()))\n",
    "        #        continue\n",
    "        #    else:\n",
    "        #        molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "        #        keep.append(True)    \n",
    "        #else:\n",
    "        #    keep.append(False)\n",
    "            #keep += 1\n",
    "        #molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "        #keep += 1\n",
    "\n",
    "\n",
    "print(molded_masks.shape)\n",
    "result_scores=r['scores'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_masks=molded_masks[:,:,keep]\n",
    "result_class_ids=r['class_ids'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_rois=r['rois'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_masks=refine_masks(result_masks,result_scores)\n",
    "#molded_masks=molded_masks[:,:,:keep]\n",
    "\n",
    "#class_ids=r['class_ids'][:keep]\n",
    "import cv2\n",
    "res = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "#print(rois.shape,class_ids.shape,molded_masks.shape)\n",
    "#visualize.display_instances(img, result_rois, result_masks, result_class_ids, \n",
    "#                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(img, result_rois, result_masks, result_class_ids, \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bboxs=r['rois']\n",
    "#raw_masks=r['raw_masks']\n",
    "#molded_masks=r['masks']\n",
    "\n",
    "keep=[]\n",
    "\n",
    "for i in range(raw_masks.shape[-1]):\n",
    "    if r['scores'][i] > THRESHOLD_SCORE:\n",
    "        img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "        mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "        molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "\n",
    "        if portion(molded_mask) < 0.20:\n",
    "            if portion(molded_mask) < 0.05:\n",
    "                keep.append(False)\n",
    "                continue\n",
    "            print(portion(molded_mask))\n",
    "            keep.append(True)\n",
    "            continue\n",
    "        mask_seg = mask_seg+1e-9\n",
    "        Q = dense_crf(img_seg,mask_seg)\n",
    "        if Q.sum() > 0:\n",
    "            if abs((portion(molded_mask)-portion(Q))/portion(molded_mask)) > 0.3:\n",
    "                keep.append(True)\n",
    "                print(i,abs((portion(molded_mask)-portion(Q))/portion(molded_mask)))\n",
    "                continue\n",
    "            else:\n",
    "                print(i,abs((portion(molded_mask)-portion(Q))/portion(molded_mask)))\n",
    "                molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "                keep.append(True)    \n",
    "        else:\n",
    "        #    print(i)\n",
    "            keep.append(False)\n",
    "            #keep += 1\n",
    "        #molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "        #keep += 1\n",
    "\n",
    "\n",
    "print(molded_masks.shape)\n",
    "result_scores=r['scores'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_masks=molded_masks[:,:,keep]\n",
    "result_class_ids=r['class_ids'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_rois=r['rois'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "result_masks=refine_masks(result_masks,result_scores)\n",
    "bboxs=r['rois'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "#molded_masks=molded_masks[:,:,:keep]\n",
    "\n",
    "keep=[]\n",
    "for i in range(result_masks.shape[-1]):   \n",
    "    molded_mask=result_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "    if portion(molded_mask) < 0.05:\n",
    "        print(i,portion(molded_mask))\n",
    "        keep.append(False)\n",
    "        continue\n",
    "         \n",
    "    keep.append(True)\n",
    "print(keep)\n",
    "result_scores=result_scores[keep]\n",
    "result_masks=result_masks[:,:,keep]\n",
    "result_class_ids=result_class_ids[keep]\n",
    "result_rois=result_rois[keep]\n",
    "result_masks=refine_masks(result_masks,result_scores)\n",
    "\n",
    "import cv2\n",
    "res = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "#print(rois.shape,class_ids.shape,molded_masks.shape)\n",
    "#visualize.display_instances(img, result_rois, result_masks, result_class_ids, \n",
    "#                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(img, result_rois, result_masks, result_class_ids, \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "IMAGE_SIZE=512\n",
    "res_img = cv2.resize(img, dsize=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "res_masks=np.zeros((IMAGE_SIZE,IMAGE_SIZE,result_masks.shape[-1]))\n",
    "for m in range(result_masks.shape[-1]):\n",
    "    res_masks[:, :, m] = cv2.resize(result_masks[:, :, m].astype('uint8'), (IMAGE_SIZE,IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "y_scale=IMAGE_SIZE/img.shape[0]\n",
    "x_scale=IMAGE_SIZE/img.shape[1]\n",
    "res_rois = (result_rois * [y_scale, x_scale, y_scale, x_scale]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(res_img, res_rois, res_masks, result_class_ids, \n",
    "                            class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Convert data to run-length encoding\n",
    "def to_rle(bits):\n",
    "    rle = []\n",
    "    pos = 0\n",
    "    for bit, group in itertools.groupby(bits):\n",
    "        group_list = list(group)\n",
    "        if bit:\n",
    "            rle.extend([pos, int(sum(group_list))])\n",
    "        pos += len(group_list)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESHOLD_SCORE=0.1\n",
    "\n",
    "sub_list = []\n",
    "missing_count = 0\n",
    "for i_, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    #image = resize_image(str(DATA_DIR/'test'/row['ImageId']))\n",
    "    img = np.array(Image.open(DATA_DIR+\"/test/\"+row['ImageId']))\n",
    "    \n",
    "    height,width,_=img.shape\n",
    "    if height*width > (1024*1024):\n",
    "        resize_scale=math.sqrt((height*width)/(1024*1024))\n",
    "        new_height = int(height/resize_scale)\n",
    "        new_width = int(width/resize_scale)\n",
    "\n",
    "        img = cv2.resize(img, dsize=(new_width,new_height))   \n",
    "    \n",
    "    \n",
    "    r = model.detect([img])[0]\n",
    "    if r['masks'].size > 0 and r['scores'][r['scores']>THRESHOLD_SCORE].size > 0:\n",
    "        molded_masks=r['masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        raw_masks=r['raw_masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        molded_masks=refine_masks(molded_masks,r['scores'][r['scores']>THRESHOLD_SCORE])\n",
    "        bboxs=r['rois']\n",
    "        \n",
    "        keep=[]\n",
    "\n",
    "        for i in range(raw_masks.shape[-1]):\n",
    "            if r['scores'][i] > THRESHOLD_SCORE:\n",
    "                img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                if portion(molded_mask) < 0.2:\n",
    "                    if portion(molded_mask) < 0.05:\n",
    "                        keep.append(False)\n",
    "                        continue\n",
    "                    keep.append(True)\n",
    "                    continue\n",
    "                mask_seg = mask_seg+1e-9\n",
    "                Q = dense_crf(img_seg,mask_seg)\n",
    "                if Q.sum() > 0:\n",
    "                    if abs(portion(molded_mask)-portion(Q)/portion(molded_mask)) > 0.3:\n",
    "                        keep.append(True)\n",
    "                        continue\n",
    "                    else:\n",
    "                        molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "                        keep.append(True)     \n",
    "                else:\n",
    "                    keep.append(False)\n",
    "                    #keep += 1\n",
    "                #molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "                #keep += 1\n",
    "\n",
    "\n",
    "        #print(molded_masks.shape)\n",
    "        result_scores=r['scores'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "        result_masks=molded_masks[:,:,keep]\n",
    "        result_class_ids=r['class_ids'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "        #result_rois=r['rois'][r['scores']>0.8][keep]\n",
    "        result_masks=refine_masks(result_masks,result_scores)\n",
    "        bboxs=r['rois'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "        #molded_masks=molded_masks[:,:,:keep]\n",
    "\n",
    "        keep=[]\n",
    "        for i in range(result_masks.shape[-1]):   \n",
    "            molded_mask=result_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "            if portion(molded_mask) < 0.05:\n",
    "                keep.append(False)\n",
    "                continue\n",
    "\n",
    "            keep.append(True)\n",
    "        result_scores=result_scores[keep]\n",
    "        result_masks=result_masks[:,:,keep]\n",
    "        result_class_ids=result_class_ids[keep]\n",
    "        #result_rois=result_rois[keep]\n",
    "        result_masks=refine_masks(result_masks,result_scores)        \n",
    "        \n",
    "        \n",
    "    \n",
    "        IMAGE_SIZE=512\n",
    "        #res_img = cv2.resize(img, dsize=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        res_masks=np.zeros((IMAGE_SIZE,IMAGE_SIZE,result_masks.shape[-1]))\n",
    "        for m in range(result_masks.shape[-1]):\n",
    "            res_masks[:, :, m] = cv2.resize(result_masks[:, :, m].astype('uint8'), (IMAGE_SIZE,IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "        #y_scale=IMAGE_SIZE/img.shape[0]\n",
    "        #x_scale=IMAGE_SIZE/img.shape[1]\n",
    "        #res_rois = (result_rois * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
    "        #print(res_masks.shape[-1])\n",
    "        \n",
    "        res_masks=refine_masks(res_masks,result_scores)\n",
    "        \n",
    "        for m in range(res_masks.shape[-1]):\n",
    "\n",
    "            mask = res_masks[:, :, m].ravel(order='F')\n",
    "            rle = to_rle(mask)\n",
    "            label = result_class_ids[m] - 1\n",
    "            sub_list.append([row['ImageId'], ' '.join(list(map(str, rle))), label])    \n",
    "        \n",
    "    else:\n",
    "        # The system does not allow missing ids, this is an easy way to fill them \n",
    "        sub_list.append([row['ImageId'], '1 1', 23])\n",
    "        missing_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\n",
    "print(\"Total image results: \", submission_df['ImageId'].nunique())\n",
    "print(\"Missing Images: \", missing_count)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"advanced_ML/fashion_submission8.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df= pd.read_csv(\"advanced_ML/fashion_submission_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(float('4.0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(list(map(str,[int(float(i)) for i in sub_df.iloc[0].EncodedPixels.split()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.EncodedPixels.apply(lambda x: len([int(float(i)) for i in str(x).split() if float(i)!=float('nan')])).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(list(map(str,[int(float(i)) for i in sub_df.iloc[0].EncodedPixels.split()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i_, row in tqdm(sub_df.iterrows(), total=len(sample_df)):\n",
    "    if i_ > 0:\n",
    "        break\n",
    "    print(row.EncodedPixels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESHOLD_SCORE=0.1\n",
    "\n",
    "sub_list = []\n",
    "missing_count = 0\n",
    "for i_, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "\n",
    "    \n",
    "    #image = resize_image(str(DATA_DIR/'test'/row['ImageId']))\n",
    "    img = np.array(Image.open(DATA_DIR+\"/test/\"+row['ImageId']))\n",
    "    \n",
    "    height,width,_=img.shape\n",
    "    if height*width > (1024*1024):\n",
    "        resize_scale=math.sqrt((height*width)/(1024*1024))\n",
    "        new_height = int(height/resize_scale)\n",
    "        new_width = int(width/resize_scale)\n",
    "\n",
    "        img = cv2.resize(img, dsize=(new_width,new_height))   \n",
    "    \n",
    "    \n",
    "    \n",
    "    r = model.detect([img])[0]\n",
    "    if r['masks'].size > 0 and r['scores'][r['scores']>THRESHOLD_SCORE].size > 0:\n",
    "        molded_masks=r['masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        raw_masks=r['raw_masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        molded_masks=refine_masks(molded_masks,r['scores'][r['scores']>THRESHOLD_SCORE])\n",
    "        bboxs=r['rois']\n",
    "        \n",
    "        keep=[]\n",
    "\n",
    "        for i in range(raw_masks.shape[-1]):\n",
    "            if r['scores'][i] > THRESHOLD_SCORE:\n",
    "                img_seg=img[bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                mask_seg=raw_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                molded_mask=molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]\n",
    "                if portion(molded_mask) < 0.2:\n",
    "                    if portion(molded_mask) < 0.05:\n",
    "                        keep.append(False)\n",
    "                        continue\n",
    "                keep.append(True)\n",
    "                    \n",
    "                \n",
    "                #mask_seg = mask_seg+1e-9\n",
    "                #Q = dense_crf(img_seg,mask_seg)\n",
    "                #if Q.sum() > 0:\n",
    "                #    if abs(portion(molded_mask)-portion(Q)/portion(molded_mask)) > 0.5:\n",
    "                #        keep.append(True)\n",
    "                #        continue\n",
    "                #    else:\n",
    "                #        molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "                #        keep.append(True)     \n",
    "                #else:\n",
    "                #    keep.append(False)\n",
    "                    #keep += 1\n",
    "                #molded_masks[:,:,i][bboxs[i][0]:bboxs[i][2],bboxs[i][1]:bboxs[i][3]]=Q\n",
    "                #keep += 1\n",
    "        #print(keep)\n",
    "\n",
    "        #print(molded_masks.shape)\n",
    "        result_scores=r['scores'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "        result_masks=molded_masks[:,:,keep]\n",
    "        result_class_ids=r['class_ids'][r['scores']>THRESHOLD_SCORE][keep]\n",
    "        #result_rois=r['rois'][r['scores']>0.8][keep]\n",
    "        result_masks=refine_masks(result_masks,result_scores)        \n",
    "    \n",
    "        IMAGE_SIZE=512\n",
    "        #res_img = cv2.resize(img, dsize=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        res_masks=np.zeros((IMAGE_SIZE,IMAGE_SIZE,result_masks.shape[-1]))\n",
    "        for m in range(result_masks.shape[-1]):\n",
    "            res_masks[:, :, m] = cv2.resize(result_masks[:, :, m].astype('uint8'), (IMAGE_SIZE,IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "        #y_scale=IMAGE_SIZE/img.shape[0]\n",
    "        #x_scale=IMAGE_SIZE/img.shape[1]\n",
    "        #res_rois = (result_rois * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
    "        #print(res_masks.shape[-1])\n",
    "        \n",
    "        res_masks=refine_masks(res_masks,result_scores)\n",
    "        \n",
    "        for m in range(res_masks.shape[-1]):\n",
    "            mask = res_masks[:, :, m].ravel(order='F')\n",
    "            rle = to_rle(mask)\n",
    "            label = result_class_ids[m] - 1\n",
    "            sub_list.append([row['ImageId'], ' '.join(list(map(str, rle))), label])    \n",
    "        \n",
    "    else:\n",
    "        # The system does not allow missing ids, this is an easy way to fill them \n",
    "        sub_list.append([row['ImageId'], '1 1', 23])\n",
    "        missing_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\n",
    "print(\"Total image results: \", submission_df['ImageId'].nunique())\n",
    "print(\"Missing Images: \", missing_count)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"advanced_ML/fashion_submission_no_crf_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_df = pd.read_csv(\"advanced_ML/submission_no_crf_1.csv\")\n",
    "\n",
    "submission_df=prev_df.append(submission_df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "submission_df.to_csv(\"advanced_ML/fashion_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the submission system does not permit overlapped masks, we have to fix them\n",
    "def refine_masks_area(masks, rois):\n",
    "    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n",
    "    mask_index = np.argsort(areas)\n",
    "    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n",
    "    for m in mask_index:\n",
    "        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n",
    "        union_mask = np.logical_or(masks[:, :, m], union_mask)\n",
    "    for m in range(masks.shape[-1]):\n",
    "        mask_pos = np.where(masks[:, :, m]==True)\n",
    "        if np.any(mask_pos):\n",
    "            y1, x1 = np.min(mask_pos, axis=1)\n",
    "            y2, x2 = np.max(mask_pos, axis=1)\n",
    "            rois[m, :] = [y1, x1, y2, x2]\n",
    "    return masks, rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESHOLD_SCORE=0.7\n",
    "\n",
    "sub_list = []\n",
    "missing_count = 0\n",
    "for i_, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "\n",
    "    \n",
    "    #image = resize_image(str(DATA_DIR/'test'/row['ImageId']))\n",
    "    img = np.array(Image.open(DATA_DIR+\"/test/\"+row['ImageId']))\n",
    "    \n",
    "    height,width,_=img.shape\n",
    "    if height*width > (1024*1024):\n",
    "        resize_scale=math.sqrt((height*width)/(1024*1024))\n",
    "        new_height = int(height/resize_scale)\n",
    "        new_width = int(width/resize_scale)\n",
    "\n",
    "        img = cv2.resize(img, dsize=(new_width,new_height))   \n",
    "    \n",
    "    \n",
    "    \n",
    "    r = model.detect([img])[0]\n",
    "    if r['masks'].size > 0 and r['scores'][r['scores']>THRESHOLD_SCORE].size > 0:\n",
    "        molded_masks=r['masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        #raw_masks=r['raw_masks'][:,:,r['scores']>THRESHOLD_SCORE]\n",
    "        molded_masks, _ =refine_masks_area(molded_masks,r['rois'][r['scores']>THRESHOLD_SCORE])\n",
    "        #bboxs=r['rois']       \n",
    "    \n",
    "        IMAGE_SIZE=512\n",
    "        #res_img = cv2.resize(img, dsize=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        res_masks=np.zeros((IMAGE_SIZE,IMAGE_SIZE,result_masks.shape[-1]))\n",
    "        for m in range(result_masks.shape[-1]):\n",
    "            res_masks[:, :, m] = cv2.resize(result_masks[:, :, m].astype('uint8'), (IMAGE_SIZE,IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "        #y_scale=IMAGE_SIZE/img.shape[0]\n",
    "        #x_scale=IMAGE_SIZE/img.shape[1]\n",
    "        #res_rois = (result_rois * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
    "        #print(res_masks.shape[-1])\n",
    "        \n",
    "        #res_masks=refine_masks(res_masks,result_scores)\n",
    "        \n",
    "        for m in range(res_masks.shape[-1]):\n",
    "            mask = res_masks[:, :, m].ravel(order='F')\n",
    "            rle = to_rle(mask)\n",
    "            label = result_class_ids[m] - 1\n",
    "            sub_list.append([row['ImageId'], ' '.join(list(map(str, rle))), label])    \n",
    "        \n",
    "    else:\n",
    "        # The system does not allow missing ids, this is an easy way to fill them \n",
    "        sub_list.append([row['ImageId'], '1 1', 23])\n",
    "        missing_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\n",
    "print(\"Total image results: \", submission_df['ImageId'].nunique())\n",
    "print(\"Missing Images: \", missing_count)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"advanced_ML/fashion_submission_no_crf_4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
