{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "sess = tf.Session(config=config)\n",
    "#K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tower_0_2/MatMul:0\", shape=(2, 2), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"tower_1_2/MatMul:0\", shape=(2, 2), dtype=float32, device=/device:GPU:1)\n",
      "Tensor(\"tower_1_2/MatMul:0\", shape=(2, 2), dtype=float32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "outputs_all = []\n",
    "\n",
    "for i in range(2):\n",
    "    with tf.device('/gpu:%d' % i):\n",
    "        with tf.name_scope('tower_%d' % i):\n",
    "            #outputs_all.append([i+1] * i)\n",
    "            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "            c = tf.matmul(a, b)\n",
    "            print(c)\n",
    "            outputs_all.append(c)\n",
    "'''\n",
    "merged = []\n",
    "with tf.device('/cpu:0'):\n",
    "    for op in outputs_all:\n",
    "         tf.Concatenate(op)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(c)\n",
    "'''\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tower_1_1/MatMul:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       for i in range(self.gpu_count):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('tower_%d' % i):\n",
    "                    # Run a slice of inputs through this replica\n",
    "                    zipped_inputs = zip(self.inner_model.input_names,\n",
    "                                        self.inner_model.inputs)\n",
    "                    inputs = [\n",
    "                        KL.Lambda(lambda s: input_slices[name][i],\n",
    "                                  output_shape=lambda s: (None,) + s[1:])(tensor)\n",
    "                        for name, tensor in zipped_inputs]\n",
    "                    # Create the model replica and get the outputs\n",
    "                    outputs = self.inner_model(inputs)\n",
    "                    if not isinstance(outputs, list):\n",
    "                        outputs = [outputs]\n",
    "                    # Save the outputs for merging back together later\n",
    "                    for l, o in enumerate(outputs):\n",
    "                        outputs_all[l].append(o)\n",
    "\n",
    "        # Merge outputs on CPU\n",
    "        with tf.device('/cpu:0'):\n",
    "            merged = []\n",
    "            for outputs, name in zip(outputs_all, output_names):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    " \n",
    "shape=(int(10000),int(10000))\n",
    " \n",
    "with tf.device(\"/gpu:0\"):\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    " \n",
    "startTime = datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "        result = session.run(sum_operation)\n",
    "        print(result)\n",
    " \n",
    "print(\"\\n\" * 2)\n",
    "print(\"Time taken:\", datetime.now() - startTime)\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls fashion/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "import glob\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "input_dir = \"./fashion/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classid2label(class_id):\n",
    "    category, *attribute = class_id.split(\"_\")\n",
    "    return category, attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2df(data):\n",
    "    df = pd.DataFrame()\n",
    "    for index, el in enumerate(data):\n",
    "        for key, val in el.items():\n",
    "            df.loc[index, key] = val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls fashion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"fashion/input/\"\n",
    "train_df = pd.read_csv(input_dir + \"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_dir + \"label_descriptions.json\") as f:\n",
    "    label_description = json.load(f)\n",
    "    \n",
    "print(\"this dataset info\")\n",
    "print(json.dumps(label_description[\"info\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = json2df(label_description[\"categories\"])\n",
    "category_df[\"id\"] = category_df[\"id\"].astype(int)\n",
    "category_df[\"level\"] = category_df[\"level\"].astype(int)\n",
    "attribute_df = json2df(label_description[\"attributes\"])\n",
    "attribute_df[\"id\"] = attribute_df[\"id\"].astype(int)\n",
    "attribute_df[\"level\"] = attribute_df[\"level\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category Labels\")\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attribute Labels\")\n",
    "attribute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rle_encoding=train_df['EncodedPixels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_category = Counter()\n",
    "counter_attribute = Counter()\n",
    "for class_id in train_df[\"ClassId\"]:\n",
    "    category, attribute = classid2label(class_id)\n",
    "    counter_category.update([category])\n",
    "    counter_attribute.update(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name_dict = {}\n",
    "for i in label_description[\"categories\"]:\n",
    "    category_name_dict[str(i[\"id\"])] = i[\"name\"]\n",
    "attribute_name_dict = {}\n",
    "for i in label_description[\"attributes\"]:\n",
    "    attribute_name_dict[str(i[\"id\"])] = i[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR=\"fashion/mrcnn\"\n",
    "DATA_DIR=\"fashion/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(utils.Dataset):\n",
    "    def load_fashion(self,image_ids=None,num_data=None):\n",
    "        '''\n",
    "        add_class --> register 46 classes self.add_class('fashion',i,name)\n",
    "        image_ids --> unique index of images(name?)\n",
    "        self.add_image('fashion',image_ids,width,height,annotations)\n",
    "        width,height --> shape[:2] or extract form dataframe\n",
    "        annotations --> all collections of annotations for each image\n",
    "        Todo:\n",
    "        There are some rows that have height and weight as nan value\n",
    "        validation option is necessary for training\n",
    "        '''\n",
    "        for i,row in category_df.iterrows():\n",
    "            self.add_class('fashion',i,row['name'])\n",
    "        \n",
    "        if image_ids is None:\n",
    "            image_ids = list(set(train_df['ImageId']))\n",
    "        \n",
    "        if num_data is not None:\n",
    "            random.seed(42)\n",
    "            random.shuffle(image_ids)\n",
    "            image_ids=image_ids[:num_data]\n",
    "            \n",
    "            \n",
    "        for i in image_ids:\n",
    "            Width = train_df[train_df['ImageId']==i]['Width'].reset_index(drop=True)[0]\n",
    "            Height = train_df[train_df['ImageId']==i]['Height'].reset_index(drop=True)[0]\n",
    "            self.add_image('fashion',\n",
    "                           image_id=i,\n",
    "                           path=DATA_DIR+'/train/'+i,\n",
    "                           width=Width,\n",
    "                           height=Height,\n",
    "                           annotations=train_df[train_df['ImageId']==i])\n",
    "        \n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        ImagePath = info['path']\n",
    "        image = np.asarray(Image.open(ImagePath).convert(\"RGB\"))\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        width=info['width']\n",
    "        height=info['height']\n",
    "        \n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for i,annotation in annotations.iterrows():\n",
    "            class_id=annotation['ClassId']\n",
    "            class_id=class_id.split('_')[0]\n",
    "            class_ids.append(class_id)\n",
    "            rle = annotation['EncodedPixels']\n",
    "            instance_masks.append(self.rle_to_mask(rle,width,height))\n",
    "            \n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)+1\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            # Call super class to return an empty mask\n",
    "            return super(FashionDataset, self).load_mask(image_id)\n",
    "        \n",
    "        \n",
    "    def rle_to_mask(self,rle,width,height):\n",
    "        mask = np.zeros(width*height,dtype=np.int8)\n",
    "        pixels_list = list(map(int,rle.split(\" \")))\n",
    "        for i in range(0,len(pixels_list),2):\n",
    "            start_pixel = pixels_list[i]-1\n",
    "            num_pixel = pixels_list[i+1]-1\n",
    "            mask[start_pixel:start_pixel+num_pixel] = 1\n",
    "        \n",
    "        mask = mask.reshape((height,width),order='F')\n",
    "        return mask\n",
    "    \n",
    "    def load_attributes(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        \n",
    "        return annotations['ClassId'].apply(lambda x: x.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids_list = list(set(train_df['ImageId']))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(image_ids_list)\n",
    "\n",
    "val_split = 0.1\n",
    "split = int((1-val_split)*len(image_ids_list))\n",
    "\n",
    "train_ids = image_ids_list[:split]\n",
    "val_ids = image_ids_list[split:]\n",
    "train_ids = train_ids[:100]\n",
    "val_ids = val_ids[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset = FashionDataset()\n",
    "fashion_dataset.load_fashion(num_data=100)\n",
    "fashion_dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset_train = FashionDataset()\n",
    "fashion_dataset_train.load_fashion(train_ids)\n",
    "fashion_dataset_val = FashionDataset()\n",
    "fashion_dataset_val.load_fashion(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset_train.prepare()\n",
    "fashion_dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image Count: {}\".format(len(fashion_dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(fashion_dataset.num_classes))\n",
    "for i, info in enumerate(fashion_dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(fashion_dataset.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = fashion_dataset.load_image(image_id)\n",
    "    mask, class_ids = fashion_dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, fashion_dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "image_id = random.choice(fashion_dataset.image_ids)\n",
    "image = fashion_dataset.load_image(image_id)\n",
    "mask, class_ids = fashion_dataset.load_mask(image_id)\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, fashion_dataset.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "# Display image and instances\n",
    "visualize.display_instances(image, bbox, mask, class_ids, fashion_dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 1))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "'''\n",
    "def rle_to_mask(rle,width,height):\n",
    "    mask = np.zeros(width*height,dtype=np.int8)\n",
    "    pixels_list = list(map(int,rle.split(\" \")))\n",
    "    for i in range(0,len(pixels_list),2):\n",
    "        start_pixel = pixels_list[i]-1\n",
    "        num_pixel = pixels_list[i+1]-1\n",
    "        mask[start_pixel:start_pixel+num_pixel] = 1\n",
    "        \n",
    "    mask = mask.reshape((height,width),order='F')\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "m=rle_to_mask(sample_rle_encoding,3676,5214)\n",
    "r=rle_encoding(m)\n",
    "\n",
    "\" \".join([str(e) for e in r]) == sample_rle_encoding\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(mask):\n",
    "    \"\"\"Compute bounding boxes from masks.\n",
    "    mask: [height, width, num_instances]. Mask pixels are either 1 or 0.\n",
    "    Returns: bbox array [num_instances, (y1, x1, y2, x2)].\n",
    "    \"\"\"\n",
    "    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n",
    "    for i in range(mask.shape[-1]):\n",
    "        m = mask[:, :, i]\n",
    "        # Bounding box.\n",
    "        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n",
    "        vertical_indicies = np.where(np.any(m, axis=1))[0]\n",
    "        if horizontal_indicies.shape[0]:\n",
    "            x1, x2 = horizontal_indicies[[0, -1]]\n",
    "            y1, y2 = vertical_indicies[[0, -1]]\n",
    "            # x2 and y2 should not be part of the box. Increment by 1.\n",
    "            x2 += 1\n",
    "            y2 += 1\n",
    "        else:\n",
    "            # No mask for this instance. Might happen due to\n",
    "            # resizing or cropping. Set bbox to zeros\n",
    "            x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "        boxes[i] = np.array([y1, x1, y2, x2])\n",
    "    return boxes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset.load_attributes(98)[np.array([False]*7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks,class_ids=fashion_dataset.load_mask(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset.load_attributes(98)[class_ids<13].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[:,:,class_ids<13].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes_test=[]\n",
    "for id in fashion_dataset.image_ids:\n",
    "    masks,class_ids=fashion_dataset.load_mask(id)\n",
    "    masks = masks[:,:,class_ids<13]\n",
    "    bb=extract_bboxes(masks)\n",
    "    bounding_boxes_test.append(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0=fashion_dataset.load_image(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr0=[]\n",
    "for bb in bounding_boxes_test[3]:\n",
    "    tr0.append(s0[bb[0]:bb[2],bb[1]:bb[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(tr0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_class_id_df=train_df[train_df.ClassId.apply(lambda x: len(x.split('_')))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_class_id_df.ClassId.apply(lambda x: x.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_phase2(dataset, shuffle=True,batch_size=1):\n",
    "    b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    image_ids = np.copy(dataset.image_ids)\n",
    "    error_count = 0\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % len(image_ids)\n",
    "            if shuffle and image_index == 0:\n",
    "                np.random.shuffle(image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = image_ids[image_index]\n",
    "            \n",
    "            masks,class_ids = dataset.load_mask(image_id)\n",
    "            attributes = dataset.load_attributes(image_id)[class_ids<13].tolist()#first element must be ignored\n",
    "            \n",
    "            masks = masks[:,:,class_ids<13]\n",
    "            \n",
    "            bbs = extract_bboxes(masks)\n",
    "            \n",
    "            original_img = dataset.load_image(image_id)\n",
    "\n",
    "            for i,bb in enumerate(bbs):\n",
    "                input_seg = original_img[bb[0]:bb[2],bb[1]:bb[3]]\n",
    "                outputs = np.zeros((batch_size,92),dtype=np.int8)\n",
    "                flag=False\n",
    "                for i,index in enumerate(attributes[i]):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    outputs[b,int(index)]=1\n",
    "                    flag=True\n",
    "                \n",
    "                if flag:\n",
    "                    print(outputs)\n",
    "                \n",
    "                b += 1\n",
    "                \n",
    "                if b >= batch_size:\n",
    "                    \n",
    "                    yield input_seg,outputs\n",
    "                    b=0\n",
    "                    \n",
    "                    \n",
    "        except (GeneratorExit, KeyboardInterrupt):\n",
    "            raise\n",
    "        except:\n",
    "            error_count += 1\n",
    "            if error_count > 5:\n",
    "                raise        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_gen=data_generator_phase2(fashion_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0,100):\n",
    "    inputs,outputs=next(phase2_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "how many examples under class id 12 have attributes?\n",
    "All object --> 11540/77019 ~ 14%\n",
    "picture 6696/45587 ~ 14%\n",
    "Data augmentation?\n",
    "-->multilabel classification\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Todo: make dataset for attribute predictor\n",
    "\n",
    "attribute_data_generator(dataset,~~~) // dataset --> Fashiondataset\n",
    "\n",
    "fit_generator! class_id < 13! fit_generator(attribute_data_generator,~~~)\n",
    "while True:\n",
    "    img_index = (img_index+1) % len(img_ids)\n",
    "    if img_index == 0:\n",
    "        np.ramdom.shuffle(img_ids)\n",
    "    img_id = img_ids[img_index]\n",
    "    \n",
    "    for object in img_id:\n",
    "\n",
    "        ...\n",
    "        \n",
    "        yield input,output\n",
    "        \n",
    "\n",
    "Attribute --> long_class_id_df\n",
    "encoded pixels --> bounding box\n",
    "(width,height,channels),(class_num(92))\n",
    "extract bounding box --> feed into model\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "def extract_bboxes(mask):\n",
    "    \"\"\"Compute bounding boxes from masks.\n",
    "    mask: [height, width, num_instances]. Mask pixels are either 1 or 0.\n",
    "    Returns: bbox array [num_instances, (y1, x1, y2, x2)].\n",
    "    \"\"\"\n",
    "    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n",
    "    for i in range(mask.shape[-1]):\n",
    "        m = mask[:, :, i]\n",
    "        # Bounding box.\n",
    "        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n",
    "        vertical_indicies = np.where(np.any(m, axis=1))[0]\n",
    "        if horizontal_indicies.shape[0]:\n",
    "            x1, x2 = horizontal_indicies[[0, -1]]\n",
    "            y1, y2 = vertical_indicies[[0, -1]]\n",
    "            # x2 and y2 should not be part of the box. Increment by 1.\n",
    "            x2 += 1\n",
    "            y2 += 1\n",
    "        else:\n",
    "            # No mask for this instance. Might happen due to\n",
    "            # resizing or cropping. Set bbox to zeros\n",
    "            x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "        boxes[i] = np.array([y1, x1, y2, x2])\n",
    "    return boxes.astype(np.int32)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class SpatialPyramidPooling(Layer):\n",
    "    \"\"\"Spatial pyramid pooling layer for 2D inputs.\n",
    "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
    "    K. He, X. Zhang, S. Ren, J. Sun\n",
    "    # Arguments\n",
    "        pool_list: list of int\n",
    "            List of pooling regions to use. The length of the list is the number of pooling regions,\n",
    "            each int in the list is the number of regions in that pool. For example [1,2,4] would be 3\n",
    "            regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n",
    "    # Output shape\n",
    "        2D tensor with shape:\n",
    "        `(samples, channels * sum([i * i for i in pool_list])`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_list, **kwargs):\n",
    "\n",
    "        self.dim_ordering = K.image_dim_ordering()\n",
    "        assert self.dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
    "\n",
    "        self.pool_list = pool_list\n",
    "\n",
    "        self.num_outputs_per_channel = sum([i * i for i in pool_list])\n",
    "\n",
    "        super(SpatialPyramidPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            self.nb_channels = input_shape[1]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            self.nb_channels = input_shape[3]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.nb_channels * self.num_outputs_per_channel)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'pool_list': self.pool_list}\n",
    "        base_config = super(SpatialPyramidPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "\n",
    "        input_shape = K.shape(x)\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            num_rows = input_shape[2]\n",
    "            num_cols = input_shape[3]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            num_rows = input_shape[1]\n",
    "            num_cols = input_shape[2]\n",
    "\n",
    "        row_length = [K.cast(num_rows, 'float32') / i for i in self.pool_list]\n",
    "        col_length = [K.cast(num_cols, 'float32') / i for i in self.pool_list]\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
    "                for jy in range(num_pool_regions):\n",
    "                    for ix in range(num_pool_regions):\n",
    "                        x1 = ix * col_length[pool_num]\n",
    "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
    "                        y1 = jy * row_length[pool_num]\n",
    "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
    "\n",
    "                        x1 = K.cast(K.round(x1), 'int32')\n",
    "                        x2 = K.cast(K.round(x2), 'int32')\n",
    "                        y1 = K.cast(K.round(y1), 'int32')\n",
    "                        y2 = K.cast(K.round(y2), 'int32')\n",
    "                        new_shape = [input_shape[0], input_shape[1],\n",
    "                                     y2 - y1, x2 - x1]\n",
    "                        x_crop = x[:, :, y1:y2, x1:x2]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(2, 3))\n",
    "                        outputs.append(pooled_val)\n",
    "\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
    "                for jy in range(num_pool_regions):\n",
    "                    for ix in range(num_pool_regions):\n",
    "                        x1 = ix * col_length[pool_num]\n",
    "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
    "                        y1 = jy * row_length[pool_num]\n",
    "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
    "\n",
    "                        x1 = K.cast(K.round(x1), 'int32')\n",
    "                        x2 = K.cast(K.round(x2), 'int32')\n",
    "                        y1 = K.cast(K.round(y1), 'int32')\n",
    "                        y2 = K.cast(K.round(y2), 'int32')\n",
    "\n",
    "                        new_shape = [input_shape[0], y2 - y1,\n",
    "                                     x2 - x1, input_shape[3]]\n",
    "\n",
    "                        x_crop = x[:, y1:y2, x1:x2, :]\n",
    "                        xm = K.reshape(x_crop, new_shape)\n",
    "                        pooled_val = K.max(xm, axis=(1, 2))\n",
    "                        outputs.append(pooled_val)\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            outputs = K.concatenate(outputs)\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            #outputs = K.concatenate(outputs,axis = 1)\n",
    "            outputs = K.concatenate(outputs)\n",
    "            #outputs = K.reshape(outputs,(len(self.pool_list),self.num_outputs_per_channel,input_shape[0],input_shape[1]))\n",
    "            #outputs = K.permute_dimensions(outputs,(3,1,0,2))\n",
    "            #outputs = K.reshape(outputs,(input_shape[0], self.num_outputs_per_channel * self.nb_channels))\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Activation, MaxPooling2D, Dense\n",
    "from spp.SpatialPyramidPooling import SpatialPyramidPooling\n",
    "\n",
    "batch_size = #\n",
    "num_channels = 3\n",
    "num_classes = #\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# uses theano ordering. Note that we leave the image size as None to allow multiple image sizes\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(3, None, None)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(SpatialPyramidPooling([1, 2, 4]))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "**Another choice could be tanh + hinge loss\n",
    "\n",
    "\n",
    "model.fit(np.random.rand(batch_size, width, height, num_channels), np.zeros((batch_size, num_classes)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionConfig(Config):\n",
    "\n",
    "    NAME = \"fashion\"\n",
    "\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 46\n",
    "    STEPS_PER_EPOCH=100\n",
    "    \n",
    "config = FashionConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if args.model.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        model_path = model.find_last()\n",
    "elif args.model.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        model_path = model.get_imagenet_weights()\n",
    "else:\n",
    "        model_path = args.model\n",
    "'''\n",
    "WEIGHT_PATH = 'last'\n",
    "\n",
    "if WEIGHT_PATH == \"last\":\n",
    "        # Find last trained weights\n",
    "        model_path = model.find_last()\n",
    "elif WEIGHT_PATH == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        model_path = model.get_imagenet_weights()\n",
    "else:\n",
    "        pass\n",
    "        #model_path = args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_stage1=40\n",
    "epochs_stage2=120\n",
    "epochs_stage3=160\n",
    "\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(fashion_dataset_train, fashion_dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=epochs_stage1,\n",
    "                layers='heads')\n",
    "\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(fashion_dataset_train, fashion_dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=epochs_stage2,\n",
    "            layers='4+')\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(fashion_dataset_train, fashion_dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=epochs_stage3,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(FashionConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "    \n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = train_ids[0]\n",
    "image=fashion_dataset_train.load_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.detect([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            fashion_dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_filepaths(input_dir):\n",
    "    jpg_fps = glob.glob(input_dir+'/'+'*.jpg')\n",
    "    return list(set(jpg_fps))\n",
    "\n",
    "test_input_dir=os.path.join(DATA_DIR, 'test')\n",
    "test_fps=get_test_filepaths(test_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
